\documentclass[12pt]{report}

\usepackage[a4paper,
            bindingoffset=0.5cm,
            left=2.5cm,
            right=2.5cm,
            top=5cm,
            bottom=5cm]{geometry}

\usepackage[english]{babel}
\usepackage{amsfonts}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{graphicx}
\graphicspath{ {./img/} }
\usepackage{subcaption}

\renewcommand{\chaptermark}[1]{\markboth{\thechapter. #1}{}}
\titleformat{\chapter}{\normalfont\huge\bfseries}{\thechapter}{0.35cm}{}

\renewcommand{\lstlistingname}{Source code}
\lstset{language=Python, numbers=left, numbersep=10pt, backgroundcolor=\color{lightgray}}

\usepackage{caption}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{darkgray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont={white, bf},textfont=white}

\lstdefinestyle{mystyle}
{
     frame=b,         
     belowcaptionskip=-1pt,
     xleftmargin=25pt,
     framexleftmargin=25pt,
     framexrightmargin=5pt,
     framextopmargin=5pt,
     framexbottommargin=5pt,
     framesep=0pt,
     rulesep=0pt,
     breaklines=true,
     showstringspaces=false
}

\lstset{literate=%
  {Ö}{{\"O}}1
  {Ä}{{\"A}}1
  {Ü}{{\"U}}1
  {ß}{{\ss}}1
  {ü}{{\"u}}1
  {ä}{{\"a}}1
  {ö}{{\"o}}1
} 

\begin{document}
\pagenumbering{gobble}
\vspace*{2cm}
\begin{center}
\textbf{\Huge Ray-tracing based renderer from scratch}
\end{center}
\vspace*{1cm}
\begin{figure}[h!]
\includegraphics[width=\textwidth]{title}
\end{figure}
\begin{center}
{\Large Timo Salisch}
\end{center}
\clearpage

\tableofcontents

\newpage
\chapter{Rendering loop}
\label{chp:step1}
\pagenumbering{arabic}
The rendering process consists of two loops. One outer loop which iterates through the rows of the image and the inner loop iterating through the columns of the image. This way, every pixel will be visited once and the color of the pixel can be calculated. In this basic version of the rendering loop the color of every pixel will be set to (128, 64, 255). The resulting image can be seen in figure \ref{fig:step1}.
\begin{figure}[h!]
\includegraphics[width=\textwidth]{step1}
\centering
\caption{Result after running simple rendering loop}
\label{fig:step1}
\end{figure} \\
To store the already rendered information about the image, an \textit{Image} class is implemented. An instance of this class represents one image and saves the color information of every pixel using a two dimensional list. The color is represented as an instance of the \textit{Vector} class. This \textit{Vector} class saves three floating point values and offers simple arithmetic operations of (three-dimensional) vectors. These three values can either be interpreted as the world coordinates x, y and z or as the color properties red, green and blue. To change the color value of a specific pixel of the image, the \textit{Image} class provides an \textit{update} method to do so. In order for the image to be viewed, it has to be saved. The image is saved in the ''PPM'' format. This is done by the \textit{save\_image} method which expects a path and then saves the image to that path using the ''PPM'' format. For the file to be readable as ''PPM'', the first three lines have to include: ''P3'', image width and height, max color value. The actual pixel information are added by the loop iterating through the pixels. It is import to iterate through the rows beginning with the top row, otherwise the image is flipped. The saving process can be seen in source code \ref{lst:saving}.
\begin{lstlisting}[caption={Saving an image}, label=lst:saving, style=mystyle]
def save_image(self, path: str):
    image_str = f'P3\n{self.width} {self.height}\n255'
  
    for j in range(self.height)[::-1]:
        for i in range(self.width):
            red, green, blue = self.matrix[i][j].to_tuple()
            image_str = image_str + f"\n{int(red)} {int(green)} {int(blue)}"

    with open(path, mode='w+') as f:
        f.write(image_str)
\end{lstlisting}

\chapter{Camera}
The project is extended by a \textit{Ray} and \textit{Camera} class. A ray can be used to find all objects that need to be projected onto one pixel and thus finding the color of a pixel. Every ray has an origin and a direction, with both being instances of the \textit{Vector} class. It is possible to get the position of a ray through its method \textit{position}. The camera represents the observer of the scene and has properties such as position and information about the image. The rendering loop from chapter \ref{chp:step1} is moved into the camera class. It uses the cameras properties to find the color for every pixel. This is done by sending a ray from the camera to every pixel and finding the color of this ray. Because there are no objects in the scene yet, the color of a ray is the color of the background at that position as shown in source code \ref{lst:step2}.
\begin{lstlisting}[caption={Color of ray}, label=lst:step2, style=mystyle]
def get_color(ray: Ray):
    unit_direction = ray.direction.normalize()
    t = 0.5 * (unit_direction.y + 1)
    ray_color = Vector(255, 255, 255) * (1 - t) + Vector(127.5, 178.5, 255) * t
    return ray_color
\end{lstlisting}
This results in an image which goes from light blue at the top to a white color at the bottom, as can be seen in figure \ref{fig:step2}.
\begin{figure}[h!]
\includegraphics[width=\textwidth]{step2}
\centering
\caption{Rendering with camera and colored background}
\label{fig:step2}
\end{figure}

\chapter{Objects: shape}
After adding a camera to the scene, the next logical step is to add objects. The chosen object to start with are spheres. For this a class \textit{Sphere} is implemented, which takes a vector as origin, a radius and a color vector. A \textit{Sphere} instance can return if a given ray hits it and if so, can calculate the intersection point of the ray and itself and its normal vector at that point. The normal vector is chosen to always point outwards of the sphere. If a ray hits a sphere, the ray adopts the color of the sphere. To better organize the handling of the sphere objects, a \textit{Scene} class is used. This class represents the scene and holds the camera and all objects in this scene. The objects are stored in an instance of the \textit{World} class. This class is basically an abstracted list with the benefit, that it provides a \textit{hit} method. Like the equivalent method of the \textit{Sphere} class, it determines if the ray hits an object. But this method checks all spheres and returns the information about the sphere, that gets hit by the ray first. This solves the visibility problem of multiple spheres being stacked behind each other. It also simplifies the rendering loop to not having to iterate through all spheres, because this is done internally by this method. To keep the interface simple, the \textit{Scene} class also offers a \textit{render} method which just forwards to the equivalent method of the camera. This way, all required actions can be performed using a \textit{Scene} instance which, after rendering, returns an \textit{Image} instance that can be used as needed. To change the scene after creation, it provides a function to add spheres to it. This class structure simplifies the whole process from creating to rendering and saving the image to:
\begin{itemize}
\item Creating a \textit{Camera} instance with preferred properties
\item Creating a \textit{Scene} object giving the camera instance as a parameter
\item Creating and adding as many \textit{Sphere} instances to the scene object as wanted
\item Using \textit{render} function of scene
\item Saving resulted \textit{Image} object to any path
\end{itemize}
Using this procedure, images can be created that contain multiple spheres. Every sphere can have a different color, position and size. If at a position in the image there is no sphere, the background color introduces in the previous chapter is kept. At this point the created rendered has solved the visibility problem, even though in a pretty simple setting. An example of an image created by this renderer is displayed in figure \ref{fig:step3}.
\begin{figure}[h!]
\includegraphics[width=\textwidth]{step3}
\centering
\caption{Image created by simple renderer}
\label{fig:step3}
\end{figure}

\chapter{Enhancing camera and rendering loop}
On the rendered images the spheres seem round, but this is not the actually the case. They only look round because of the ''high'' quality and thus the pixels being pretty small. By zooming into the image at the border of a sphere this can be seen more clearly (figure \ref{fig:aliasing}).
\begin{figure}[h!]
\includegraphics[width=\textwidth]{aliasing}
\centering
\caption{Zoomed in sphere border}
\label{fig:aliasing}
\end{figure} \\
The reason for this is, that only one ray is sent through each pixel at the left end of the pixel. With spheres being round in reality but monitors only being able to display things using pixels, this is no unexpected behavior. But if pixels are bigger -- either because of a lower resolution or because the images are shown on a bigger screen -- this can make the image look unnatural and wrong. One way of improving the border would be using colors in between the two colors (here red and green). This would make the edge less harsh and thus the sphere looks more round. To keep the correct shape of the objects and not adding any visual bumps to it, the color has to be mixed of the two colors keeping the ratio of the objects in this pixel into account. To not having to calculate the ratio for every pixel, which is computational expensive, multiple rays are sent through each pixel at random positions of the pixel. The average color of these rays can then be used as the color of the pixel. The more rays are used per pixel, the closer will the average color be to the true color.
\begin{figure}[h!]
\centering
\begin{subfigure}[h!]{0.475\textwidth}
\centering
\includegraphics[width=\textwidth]{step4_2rays}
\caption{2 rays per pixel}
\end{subfigure}
\hfill
\begin{subfigure}[h!]{0.475\textwidth}
\centering
\includegraphics[width=\textwidth]{step4_4rays}
\caption{4 rays per pixel}
\end{subfigure}
\vskip\baselineskip
\begin{subfigure}[h!]{0.475\textwidth}
\centering
\includegraphics[width=\textwidth]{step4_8rays}
\caption{8 rays per pixel}
\end{subfigure}
\hfill
\begin{subfigure}[h!]{0.475\textwidth}
\centering
\includegraphics[width=\textwidth]{step4_16rays}
\caption{16 rays per pixel}
\end{subfigure}
\caption{Zoomed in sphere border with a different number of rays per pixel}
\label{fig:step4}
\end{figure} \\
From figure \ref{fig:step4} can be seen, that the more rays are used per pixel the more different color shades are used at the sphere's border. In comparison to only one ray (figure \ref{fig:aliasing}), it is visible that the sphere's edge becomes much smoother the more rays are used.

\chapter{Objects material: diffuse}
The images produced so far look rather 2D than 3D, it seems like there is no depth in the image. This is caused by the uniform color of the spheres. In the real world, a sphere has reflections on it and the color looks different depending of the viewing angle. Also there are no shadows of the spheres on one another if they are close. To solve this and make the image more realistic, materials are introduced. A parent class \textit{Material} defines all methods needed for a material. Instead of a color, every sphere now gets a material that contains the color information. To make the rendered backwards compatible and being able to still recreate previous images, a \textit{NoTexture} material is implemented. This material has no texture and only has its color, simulating the appearance of spheres without materials. By doing so, a consisting interface is created where every sphere has a material and the methods provided by the \textit{Material} can always be used. Therefore, \textit{NoTexture} and all other implemented materials inherit from the \textit{Material} class. To have a simple texture for the spheres, the material \textit{Diffuse} is added. This reflects the ray, when hit by it, in a random direction following it normal vector at this point. By using the normal vector as the baseline for the reflected ray, the curvature of the sphere becomes visible. But to make it more realistic, a bit of randomness is added on top of the normal vector. The ray now does simply takes the color of the sphere it has hit, but  follows in the reflected direction to see if it hits another object there. This way, the ray that, in the normal world would come from the light source, bounce of some objects and then go into the camera, is simulated backwards. At this point, the only source of light is the background. By modulating all colors the ray encounters on its way, the final color can be determined. It is done in a way where the color components are multiplied with each other. This is realistic taking into account that complementary colors if mixed result in black in the real world and also with this modulation. The modulation is shown in source code \ref{lst:modulation}. \\\\\\
\begin{lstlisting}[caption={Modulating two colors}, label=lst:modulation, style=mystyle]
def modulate(self, other: Vector) -> Vector:
    return Vector(self.x * other.x / 255, self.y * other.y / 255, self.z * other.z / 255)
\end{lstlisting}
Because the program needs to be terminated at some point, a maximum number of times the ray can bounce of objects has to be defined. Otherwise it could occur, that the ray gets stuck between multiple objects always going from one object to the other and the program therefore never finishing. If this maximum number of bounces is reached, the color of the ray is set to black, because it did not come from a light source. The influence of the render depth (the maximum number of bounces) onto the finale image can be seen in figure \ref{fig:step5}. It can be seen, that the bigger the render depth the less noise the image appears. In the real world the light ray can bounce of unlimited time (assuming the light does not lose energy by absorption or scattering). With a higher render depth, it is more likely that the light source of the ray is found and thus the ray does not get set to black. These ''false'' black rays happen more often with a lower render depth letting the image seem noisy. A render depth of 1 is the extreme case of this, here every ray that hits an object is assumed to not come from a light source portraying all spheres as black. \\
Simply modulating as shown in source code \ref{lst:modulation} causes the rays to become darker the more often they are reflected. Because of that the image is getting darker which is not wanted. To reduce this effect, the image needs to be gamma corrected. This is done by taking the square root of the relative intensity of the color component (hence the color component in an interval of 0 to 1). The gamma correction is represented in source code \ref{lst:gamma}.
\begin{lstlisting}[caption={Gamma correction}, label=lst:gamma, style=mystyle]
red = math.sqrt(red / 255) * 255
green = math.sqrt(green / 255) * 255
blue = math.sqrt(blue / 255) * 255
\end{lstlisting}
\begin{figure}[h!]
\centering
\begin{subfigure}[h!]{0.475\textwidth}
\centering
\includegraphics[width=\textwidth]{step5_depth1}
\caption{Render depth 1}
\end{subfigure}
\hfill
\begin{subfigure}[h!]{0.475\textwidth}
\centering
\includegraphics[width=\textwidth]{step5_depth2}
\caption{Render depth 2}
\end{subfigure}
\vskip\baselineskip
\begin{subfigure}[h!]{0.475\textwidth}
\centering
\includegraphics[width=\textwidth]{step5_depth4}
\caption{Render depth 4}
\end{subfigure}
\hfill
\begin{subfigure}[h!]{0.475\textwidth}
\centering
\includegraphics[width=\textwidth]{step5_depth8}
\caption{Render depth 8}
\end{subfigure}
\vskip\baselineskip
\begin{subfigure}[h!]{0.475\textwidth}
\centering
\includegraphics[width=\textwidth]{step5_depth16}
\caption{Render depth 16}
\end{subfigure}
\caption{Spheres with diffuse material and different render depths}
\label{fig:step5}
\end{figure}

\chapter{Objects material: specular}
jhfjgjkfgjfghjjfg

\chapter{Objects material: specular transmission}
jhfjgjkfgjfghjjfg

\chapter{Lights}
jhfjgjkfgjfghjjfg

\chapter{Positioning and orienting camera}
jhfjgjkfgjfghjjfg

\chapter{Animation}
jhfjgjkfgjfghjjfg

\chapter{Render parallelization}
jhfjgjkfgjfghjjfg

\chapter{Config files}
jhfjgjkfgjfghjjfg
\end{document}